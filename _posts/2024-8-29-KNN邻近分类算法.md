---
layout: post
title: "K-邻近算法"
date:   2024-8-29
tags: [分类问题, 机器学习, 监督学习]
comments: true
author:  HQJ
---
## 特点

- 适用多分类问题、对稀有事件进行分类（例如当流失率很低时，比如低于0.5%，构造流失预测模型）。

- 可解释性较差。

- 监督学习，需要训练数据。样本→训练模型 ，其他输入→模型→预测输出

## 重要参数

### 距离度量

特征空间中的两个实例点的距离是两个实例点相似程度的反映。K近邻法的特征空间一般是n维实数向量空间Rn。使用的距离是欧氏距离，但也可以是其他距离，如更一般的Lp距离或Minkowski距离。

     设特征空间X是n维实数向量空间$R^n$,$ x_i,x_j\in X$,$x_i=(x_i^{(1)},x_i^{(2)},\cdots,x_i^{(n)})^T $，$x_j=(x_j^{(1)},x_j^{(2)},\cdots,x_j^{(n)})^T $，$x_i,x_j$的Lp距离为
$$
L_p(x_i,x_j)=(\sum_{l=1}^{n}|{x_i}^{(l)}-{x_j}^{(l)}|^p)^{\frac{1}{p}}
$$

### k值

依据输入数据的类别多少。

### 分类依据

分类问题中以多数类决定，回归问题以输出平均值决定。